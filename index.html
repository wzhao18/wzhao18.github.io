<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Wei Zhao</title>

    <meta name="author" content="Wei Zhao">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon"> -->
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Wei Zhao
                </p>
                <p>
                  I'm a performance engineer at <a href="https://www.cerebras.ai/">Cerebras Systems</a>, where I work on optimizing the performance and efficiency of the <a href="https://www.cerebras.ai/chip/">Cerebras Wafer-Scale Engine</a> for large language model (LLM) inference.
                </p>
                <p>
                  I earned my Master's degree in Computer Science from <a href="https://www.stanford.edu/">Stanford University</a>. Before that, I received my bachelor's degree in Computer Science from the <a href="https://www.utoronto.ca/">University of Toronto</a>, where I was advised by Prof. <a href="https://www.cs.toronto.edu/~pekhimenko/"> Gennady Pekhimenko</a>.
                </p>
                <p>
                  My interest lies in building system solutions to address computational challenges in science and engineering. In the past, Iâ€™ve worked on LLM inference, GPU sharing, and stream processing systems.
                </p>
                <p style="text-align:center">
                  <a href="mailto:wzhao18.sz@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=eqb1fI0AAAAJ&hl=en&authuser=1">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/wzhao18/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/wzhao18/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%;">
                <div style="position: relative; top: 10px;">
                  <a href="images/profile-photo.jpg">
                    <img style="width:100%;max-width:100%;object-fit: cover;" alt="profile photo" src="images/profile-photo.jpg" class="hoverZoomLink">
                  </a>
                </div>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                  <span class="papertitle">Tally: Non-Intrusive Performance Isolation for Concurrent Deep Learning Workloads</span>
                <br>
                <u>Wei Zhao</u>, Anand Jayarajan, Gennady Pekhimenko 
                <br>
                <i>ASPLOS 2025 (Distinguished Artifact Award)</i>
                <br>
                  <a href="https://dl.acm.org/doi/10.1145/3669940.3707282">paper</a>&nbsp;/&nbsp;<a href="https://github.com/tally-project/tally">code</a>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                  <span class="papertitle">Seesaw: High-throughput LLM Inference via Model Re-sharding</span>
                <br>
                Qidong Su, <u>Wei Zhao</u>, Xin Li, Muralidhar Andoorveedu, Chenhao Jiang, Zhanda Zhu, Kevin Song, Christina Giannoula, Gennady Pekhimenko
                <br>
                <i>MLSys 2025 (Outstanding Paper Honorable Mention)</i>
                <br>
                  <a href="https://arxiv.org/abs/2503.06433">paper</a>&nbsp;/&nbsp;<a href="https://zenodo.org/records/14991055">code</a>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:80%;vertical-align:middle">
                  <span class="papertitle">TiLT: A Time-Centric Approach for Stream Query Optimization and Parallelization</span>
                <br>
                Anand Jayarajan, <u>Wei Zhao</u>, Yudi Sun, Gennady Pekhimenko
                <br>
                <i>ASPLOS 2023 (Distinguished Artifact Award)</i>
                <br>
                <a href="https://dl.acm.org/doi/abs/10.1145/3575693.3575704">paper</a>&nbsp;/&nbsp;<a href="https://github.com/ampersand-projects/tilt">code</a>
              </td>
            </tr>

          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website template from <a href="https://jonbarron.info/">Jon Barron</a>.<br>
                  Last updated: June 2, 2025
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
